%\documentclass[a4paper, 12pt] {article}
\documentclass[12pt,onecolumn,headsepline,numbers=noenddot,bibliography=totoc,oneside,a4paper,fleqn,BCOR8mm] {scrartcl}
\usepackage{etex}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{harvard}
\usepackage{nomencl}
\usepackage[disable]{todonotes}
%\usepackage{todonotes}
\usepackage{pgfplots}
%\usepackage[inline]{showlabels}

\pagestyle{headings}

\setlength{\unitlength}{1cm}
  \setlength{\parindent}{0cm}
  \setlength{\parskip}{1.8ex plus0.5ex minus0.5ex}
  \setlength{\baselineskip}{1.5ex plus0.5ex minus0.5ex}
  
\setlength{\textwidth}{17cm}
  \setlength{\textheight}{24cm}
  \setlength{\evensidemargin}{-0.5cm}
  \setlength{\oddsidemargin}{-0.5cm}
  \setlength{\topmargin}{-1cm}
  \setlength{\footskip }{8ex}
%%%%%%%%%%%%%%%
% TIKZ and pgfplots
%%%%%%%%%%%%%%%
\pgfplotsset{compat=1.3}
\usetikzlibrary{shapes,arrows,fit,shadows}
\tikzstyle{block} = [rectangle, draw, fill=blue!20, text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']

% Gaussian distribution
\newcommand{\optgaussian}[5][color=blue!50!black,thick]{% posx, posy, sigma, height
  \draw[#1]
  plot[smooth,domain=(-2*#4+#2):(2*#4+#2),samples=100]
  function {#3+#5*1/sqrt(2*3.1416*#4)*exp(-(x-#2)*(x-#2)/2/#4) - #5*1/sqrt(2*3.1416*#4)*exp(-(2*#4)*(2*#4)/2/#4)};
}
%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%
% AMS THEOREM ENVIRONMENTS
%%%%%%%%%%%%%%%
\newtheoremstyle{example}
{\topsep}%      Space above
{\topsep}%      Space below
{}%         Body font
{}%         Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{}%        Punctuation after thm head
{}%     Space after thm head: " " = normal interword space;
% \newline = linebreak
{\underline{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}}%         Thm head spec (can be left empty, meaning `normal')
% \theoremstyle{example}
\newtheorem*{example}{Example}
\newtheorem*{Note}{Note}
\newtheorem{thm}{Theorem}
\newtheorem{problem}{Problem}
%%%%%%%%%%%%%%%

\newcommand{\argmin}{\operatorname{argmin}}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\erf}{\operatorname{erf}} % Gaussian error function
\newcommand{\of}[1]{\mathopen{}\left(#1\right)} % for f\of{x}; \mathopen makes space shorter
\newcommand{\off}[1]{\mathopen{}\left[#1\right]} % for f\of{x}; \mathopen makes space shorter
\newcommand{\hansvec}[1]{\left[\begin{array}{c} #1 \end{array}\right]}

\makenomenclature

\begin{document}
\listoftodos
\newpage
\title{Scenario Tree Generation for Stochastic Programming}
\author{Hans Pirnay}
\maketitle
\tableofcontents
\newpage
\section{Introduction}
%\todo[inline]{write an introduction}
With the ongoing continuation of Moore's Law, previously computationally intractable problems attract researchers. Multi-Stage Stochastic Programming Problems belong to this class of problems. 

Stochastic Programming solves Optimization problems with uncertainty in the data. These problems appear naturally in many of business and engineering applications. Some examples include the operation of a power grid with stochastic demand due to consumer needs and stochastic supply due to the emergence of renewable energies such as wind and solar, which exhibit a considerable amount of uncertainty in their loads.

The scenario tree represents the future as it is seen by the optimization problem.
The generation of this scenario tree is a key step in the solution of stochastic programming problems.

In this paper, we will derive a new, powerful algorithm to generate scenario trees from arbitrary data.
This algorithm leads to a whole new perspective on the problem.

The paper is organized as follows. First, an introduction will be given to the mathematical theory of scenario tree generation. Then, two theorems on the Kantorovich distance, which will be the distance used for measuring similarity in stochastic processes, will be presented. Based on these theorems, the new algorithm will be derived. This new algorithm will shed light on some decisions made in the process of discretization of the problem, that would otherwise have gone unnoticed. The paper closes with the conclusion and some notes on possible future directions.
\begin{comment}
\section{Stochastic Programming Theory}
Consider the following real world problem:

An operator in charge of a pumped hydro plant at any given time wants to make the optimal decision whether to pump water up into his reservoir with electrical power purchased at current spot market prices, do nothing, or release water from the reservoir and sell it at the spot market. 

For an introduction into the general theory see \cite{Birge1997}. For a more recent overview on optimization under uncertainty, see \cite{Sahinidis2004} and the references therein.
% here, explain the following terms:
% - value of the stochastic solution
% - perfect foresight
% - here and now / wait and see

% \section{Scenario tree generation}
The generation of the scenario tree is a key step in the solution of stochastic programming problems.

In this paper we will present several ways to generate said scenario trees. The section is organized as follows. First, a short introduction to the basic mathematical theory will be given that is necessary to follow the derivations of the algorithms. Then, the state of the art in solving this problem is summarized. Finally, several new algorithms are derived. These new algorithms will differ from the ones proposed in the literature in that they attempt to solve the original problem to full optimality. The section will close with a discussion and comparison of the results of the presented algorithms.
\end{comment}
\include{math_foundations}
\include{naive}
\include{kantorovich_theorems}
%\include{advanced_algorithms}
\include{expectation_maximization}
\include{conclusion}
\nomenclature{$\xi$}{Stochastic Process}
\nomenclature{$\xi_i^t$}{Value of scenario $i$ of stochastic process $\xi$ at time step $t$}
\nomenclature{$\nu_i^t$}{Values of scenario $i$ of stochastic process $\nu$ at time step $t$. $\nu$ is preferably used for trees}
\nomenclature{$\Omega$}{Arbitrary set, event space}
\nomenclature{$i$}{Index, typically for sampled scenarios}
\nomenclature{$j$}{Index, typically for trees scenarios}
\nomenclature{$T$}{Number of Time steps / Index set of time steps}
\nomenclature{$I$}{Index set of sampled scenarios}
\nomenclature{$J$}{Index set of (tree) scenarios}
\nomenclature{$tr$}{The transpose of a vector/matrix}
\nomenclature{$D$}{Distance Function / metric}
\nomenclature{$D_K$}{Kantorovich Distance}
\nomenclature{$\omega$}{Event of a random variable or stochastic process, $\omega\in\Omega$}
\nomenclature{$\mathcal{F}$}{Filtration}
\nomenclature{$x$}{Free variable}
\nomenclature{$X$}{Feasible set for variable $x$ defined by its bounds}
\nomenclature{$\mathbb{E}$}{Expected value operator}
\nomenclature{$\mathbb{P}$}{Continuous probability distribution}
\nomenclature{$\mathbb{Q}$}{Continuous probability distribution}
\nomenclature{$t,\tau$}{Time step indices}
\nomenclature{$\mathfrak{P}$}{Power set operator}
\nomenclature{$\mathcal{S}$}{Set of stochastic processes}
\nomenclature{$\zeta$}{In stochastic process: Mapping from event space to value space}
\nomenclature{$c$}{Metric on the event space}
\nomenclature{$c_{ij}$}{Discrete metric on the event space}
\nomenclature{$\eta$}{Measure used in the computation of the Kantorovich Distance}
\nomenclature{$\eta_{ij}$}{Discrete measure between events/scenarios $i$ and $j$}
\nomenclature{$p,q$}{Probability distributions on discrete spaces}
\nomenclature{$\mathcal{B}$}{Borel-$\sigma$-field}
\nomenclature{$\mathcal{T}$}{Tree feasibility set}
\nomenclature{$\mathcal{P}$}{Stochastic optimization problem}
\nomenclature{$\mathcal{T}_D$}{Feasibility set for discrete event trees}
\nomenclature{$\mathcal{T}_C$}{Feasibility set for continuous event trees}
\nomenclature{$\lambda$}{Lagrange multiplier for equality constraint}
\nomenclature{$\mu$}{Lagrange multiplier for inequality constraint}
\nomenclature{$m_i$}{Optimal value of sub-problem $i$ in optimal weights proof}
\nomenclature{$K$}{Number of clusters}
\nomenclature{$f$}{Objective function}
\nomenclature{$h$}{Equality constraint}
\nomenclature{$d_1,d_2$}{Number of dimensions of the value space of a stochastic process}
\nomenclature{$L$}{Lipschitz factor}
\nomenclature{$L^p$}{Lebesgue space with norm $\Vert\cdot\Vert_p$}
\nomenclature{$\mathbb{R}$}{Set of real numbers}
\nomenclature{$n$}{Index for nodes of a tree}
\nomenclature{$e$}{Vector of ones}
\printnomenclature
\newpage
%\bibliographystyle{plain}
\bibliographystyle{agsm}
\bibliography{da}
\end{document}
