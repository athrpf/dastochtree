\subsection{Continuous decision trees}
\label{sec:naive-cont-decis-trees}
In this  section, we will present an NLP model for constructing continuous-decision trees.
Along the same lines as the previous section, we will then discuss the computational results.
We will discover that the solution of the model with traditional NLP solvers is impossible.
The reasons for their failure will be discussed.
\subsubsection{Derivation of the NLP}
Consider again a discrete stochastic process $\bs\xi(I,\mathcal{F},p)$.
Given a feasibility tree $\mathcal{T}$, the goal of this section is to find the CE-tree $\bs\chi(J,\mathcal{T}, q)\in\mathcal{S}_{CE}(\mathcal{T})$ which optimally approximates $\bs\xi$ in the Kantorovich distance.

The variables in this model are, in general, the same as in \eqref{eq:symbolic-optimization-with-minflow2} and the MILP model, but there are some differences due to the structure.
The probabilities $q_j$ of the tree will not be defined over the set of nodes, but instead over the set of the tree's scenarios $J$.
Given the probabilities of the scenarios, the probability of a node can easily be derived by adding up the probabilities of all scenarios this node belongs to.
This definition has the advantage that the probabilistic relations between nodes are automatically satisfied - for example the condition that the probability of every node has to be equal to the sum of probabilities of its children.
Similarly, the (discretized) measure $\eta_{ij}$, which will be used to calculate the Kantorovich Distance, specifies the flow between an original scenario $i \in I$ and a scenario of a tree $j \in J$.

Since the exact values of the tree's nodes are not known beforehand, the distance between the scenarios of $\bs\xi$ and $\bs\chi$ are not known either.
The distance is usually a nonlinear, non-differentiable function.
For now, we will replace it with an additional variable $c_{ij}$, and deal with modeling it below.

The objective function to be minimized is again the Kantorovich functional adopted to the particular tree structure.
\begin{equation}
  \label{eq:NLP-derivation-objective}
  \sum_{i\in I}\sum_{j\in J} \eta_{ij} c_{ij}
\end{equation}
As always, the following properties of the marginal distributions of the measure $\eta$ have to hold:
\begin{subequations}
\begin{align}
  \label{eq:eta-nlp-marginal-q}
  \sum_{i\in I}\eta_{ij} &= q_j\\
  \label{eq:eta-nlp-marginal-p}
  \sum_{j\in J}\eta_{ij} &= p_i
\end{align}
\end{subequations}
As was shown in \eqref{eq:proof-sum-q-redundant}, these equations already ensure that the probabilities $q_j$ sum to one.
The bounds
\begin{equation}
  \label{eq:bounds-nlp-q-eta}
  0 \leq \eta_{ij},\; 0\leq q_j
\end{equation}
complete the problem except for the distances $c_{ij}$.

To model the distances, a metric must be selected. The choice of the metric belongs to the domain of modeling rather than algorithmic questions that we address here. In the following, we will show how to model the distance $c_{ij}=c(\xi_i,\nu_j)$, where $\nu$ are the node values of the scenario tree $\bs\chi$, in the most common norms $\Vert\cdot\Vert_1$, $\Vert\cdot\Vert_2$, and $\Vert\cdot\Vert_\infty$.
%
\paragraph{$\infty$-norm} The $\infty$-norm is defined as the maximum over the absolute value of all components.
\begin{equation}
  \label{eq:max-c-definition}
  c_{ij} = \max\left\{\left|\xi_{ik}^t-\nu_{n(j,t)k}\right|,\; k\in D,\, t\in T\right\}\nonumber
\end{equation}
where $D=\left\{1,\, ...,\,d\right\}$ is the set of dimensional indices of the values of the stochastic process. The absolute value can be replaced by the maximum expression
\begin{equation}
  \label{eq:abs-is-a-max}
  \left|\xi_{ik}^t-\nu_{n(j,t)k}\right| = \max\limits_{l\in D}\left\{\xi_{il}^t-\nu_{n(j,t)l},\, \nu_{n(j,t)l}-\xi_{il}^t\right\}.\nonumber
\end{equation}
The maximum operator inside the maximum can, of course, be omitted. What is left is the maximum of a finite number of terms. This maximum can be expressed inside the NLP by adding $ |D| \cdot |I|\cdot |J|\cdot |T|$ pairs of inequality constraints of the form
\begin{subequations}
\begin{align}
  \label{eq:c-as-inftynorm}
  c_{ij} &\geq \xi_{ik}^t - \nu_{n(j,t)k},\\
  c_{ij} &\geq \nu_{n(j,t)k} - \xi_{ik}^t.
\end{align}
\end{subequations}
\paragraph{$\mathbf{1}$-norm} Modeling the $1$-norm in the language of inequalities is more involved, but works basically the same way as the $\infty$-norm. Additional variables $a_{ijtk}$ have to be introduced to express the absolute values of the differences in each dimension of each pair, defined by
\begin{subequations}
\begin{align}
  \label{eq:c-as-1norm-def-a}
  a_{ijtk} &\geq  \xi_{ik}^t - \nu_{n(j,t)k} \\
  a_{ijtk} &\geq  \nu_{n(j,t)k} - \xi_{ik}^t
\end{align}
The distances are then defined by
\begin{equation}
  \label{eq:c-as-1norm}
  c_{ij} = \sum_{t\in T}\sum_{k \in D} a_{ijtk}.
\end{equation}
\end{subequations}
\paragraph{$\mathbf{2}$-norm} The $2$-norm is much easier to model than the $1$-norm and the $\infty$-norm since there are no absolute values that give rise to the excessive use of additional inequality constraints.
Instead, the distance variables can be defined by the simple equations
\begin{equation}
  \label{eq:c-as-2norm}
  \left(c_{ij} \right)^2 = \sum_{t\in T}\sum_{k \in D}\left( \nu_{n(j,t)k} - \xi_{ik}^t \right)^2
\end{equation}
For our purposes, the choice is arbitrary.
For the common case of single-valued stochastic processes, the three definitions coincide.
In our implementations, we will use the formulation of the $\infty$-norm, since it offers the smallest number of additional variables while at the same time being a linear equation.
The $2$-norm has only half the number of equations, but is subject to problems in the scaling and introduces a non-linearity in the constraints, which seems favorable to avoid.

This completes the derivation of the NLP model for generating scenario trees.
The following section will be dedicated to solving this NLP.
In the next section, experiences with KKT-based solvers is discussed.
The solution is found to be problematic, with convergence and local optimality issues.
\subsubsection{Structure of the optimization problem}
In this section, the optimization problem derived in the previous section will be restated in its entirety, and its structural properties will be discussed to the degree that it is useful for solving it.
\begin{subequations}
\begin{eqnarray}
  \label{eq:full-nlp-restated-objecive}
  \min_{\eta, q, c}&&  \sum_{i\in I}\sum_{j\in J} \eta_{ij} c_{ij}\\
  \label{eq:full-nlp-restated-q}
  \mathrm{s.t.}&&\sum_{i\in I}\eta_{ij} = q_j \\
  \label{eq:full-nlp-restated-p}
  &&\sum_{j\in J}\eta_{ij} = p_i\\
  \label{eq:full-nlp-restated-ineq1}
  &&c_{ijt} \geq \xi_{ik}^t - \nu_{n(j,t)k},\\
  \label{eq:full-nlp-restated-ineq2}
  &&c_{ijt} \geq \nu_{n(j,t)k} - \xi_{ik}^t\\
  &&0 \leq \eta_{ij},\; 0\leq q_j
\end{eqnarray}
\end{subequations}
The problem is a non-convex, quadratic optimization problem. For the example of three time steps, the Hessian of the objective function has the structure
\begin{equation}
  \label{eq:structure-of-quadratic-hessian}
  Q = \left[\begin{array}{ccccc}
      0&0&0&I&0\\0&0&0&I&0\\0&0&0&I&0\\I&I&I&0&0\\0&0&0&0&0
    \end{array}\right]
\end{equation}
if the variable ordering is $(c,\eta, q)$. This matrix obviously is not positive definite. In fact, it can be found that the inertia of this matrix, meaning the triple of the numbers of positive, negative, and zero variables, is
\begin{equation}
  \label{eq:inertia-of-hessian}
  \left(n, n, T\cdot n\right)
\end{equation}
where $n=|I||J|$, and $T$ is the number of stages.
\citet{Pardalos1991} showed that quadratic optimization problems with at least one negative eigenvalue are \textbf{NP}-hard.
\subsubsection{Solution with local (KKT)-NLP solvers}
In this section, the applicability of general purpose KKT solvers to the problem stated above will be discussed. There are several issues that make this problem particularly hard to solve for KKT based solvers. Among these problems are
\begin{description}
\item[Negative Curvature] KKT solvers use first and second derivatives to generate search directions. KKT points are only stationary points, not guaranteed to be minima of the problem. In the situation of negative curvature, the local maximum is the attractor of Newton's method applied to the KKT-problem. Special care must be taken by the algorithm to reject search directions that lead to a KKT point that is a local maximizer for the objective function.
\item[Local Minima] KKT points are an inherently local property of an optimization problem. The only way to find the global optimum is through extensive spatial search. This search can be conducted by applying a deterministic KKT solver to many different, randomly selected starting points.
\item[Large Scale] Due to the complications in modeling the distances $c$, and the fact that using a greater number of original scenarios will always increase the accuracy of the approximation, the solver has to deal with a very large number of variables.
\end{description}
The interior point solver IPOPT \citep{IpoptImplementation2006} was used as the KKT solver. IPOPT is specifically designed to deal with large-scale non-convex programming problems. It has provisions that ensure global convergence to a KKT point associated with a local minimum under weak assumptions.

As is to be expected from the theoretical analysis above, solving the problem from different starting points leads to very different local minima. Figure \ref{fig:different-local-minima-with-ipopt} shows some examples of local minima the algorithm found. In addition to the locality of the solutions, the algorithm displays an unexpectedly slow convergence as the objective value of the iterates approached the optimal solution, with very large primal steps taken by the algorithm.

The reason for the poor local convergence again lies in the structure of the problem. \citet{Waechter2005} state that in order to be able to achieve superlinear local convergence, the sufficient second order conditions (SSOC) must hold for the optimal point.

One condition among these is that at the optimal point $\left(x^*,\lambda^*\right)$ the Hessian of the Lagrangean $\nabla_{xx}^2\mathcal{L}(x^*,\lambda^*)$ is positive definite when projected onto the nullspace of the constraint Jacobian matrix $\nabla c(x^*)^T$. In our specific case of a quadratic objective function with only linear constraints, the Hessian of the Lagrangean is the matrix $Q$ introduced in \eqref{eq:structure-of-quadratic-hessian}. The constraints are stated in equations \eqref{eq:full-nlp-restated-q} through \eqref{eq:full-nlp-restated-ineq2}. IPOPT does not deal directly with inequality constraints, so slack variables $s_{1ijt},\,s_{2ijt} \geq 0$ are introduced and \eqref{eq:full-nlp-restated-ineq1} and \eqref{eq:full-nlp-restated-ineq2} restated as
\begin{subequations}
\begin{align}
  \label{eq:nlp-ineq1-with-slacks}
  c_{ij} +s_{1ijt}&= \xi_{ik}^t - \nu_{n(j,t)k},\\
  c_{ij} +s_{2ijt} &= \nu_{n(j,t)k} - \xi_{ik}^t.
\end{align}
\end{subequations}
\begin{figure}
  \centering
  \includegraphics[scale=0.6]{sixgraphs}
  \caption{Six locally optimal solutions of the NLP using IPOPT, starting from random starting points. The distribution to be approximated are independent Gaussian distributions. The optimal solution would consist of each node placing its child nodes at the Gaussian quadrature points $0$ and $\pm\sqrt{3/5}$.}
  \label{fig:different-local-minima-with-ipopt}
\end{figure}
With this reformulation, the SSOC for the problem can be determined by simple algebra: There are $|J|+|I||J|+3\cdot|I||J||T|$ variables in the problem. The number of positive eigenvalues in the Hessian of the Lagrangean is $|I||J|$ (corresponds to ``$n$'' in \eqref{eq:inertia-of-hessian}. All remaining $|J|+3\cdot|I||J||T|$ have to be matched by constraints, because each constraint can only eliminate one direction. There are, however, only $2\cdot|I||J||T|+|I|+|J|$ constraints, so that a total of $|I||J||T|-|I|$ variables with eigenvalues of zero remain unmatched. These directions correspond to the distances $c_{ij}$ which are not active, e.g. these indices $i,j$ for which $\eta_{ij}=0$. For these distances, the solution is not unique, since any arbitrary feasible value chosen for them will - all else being equal - yield the same value of the objective function. Due to the barrier term that is added to the objective function, those variables $c$ will be driven arbitrarily far away from their bound, which is the behavior that was observed.

In conclusion it must be stated that this method did not seem sufficient to address the problem. Due to the abundance of local optima, some kind of global search has to be conducted. However, due to the poor convergence property of the explored algorithm, the local searches are not fast enough to be able to cover the search space in a reasonable time.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "da"
%%% End:
