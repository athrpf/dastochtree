\section{Introduction}
In recent years, the algebraic optimization models have become an important tool in many industries.
Most applications for which these models are used require decisions to be made under uncertainty.
Common examples of uncertain parameters in optimization models are future prices, future demand, and plant unit failure.
These parameter types appear in many standard optimization problems such as supply chain design given uncertain demand, and scheduling and vehicle routing with uncertain arrival times.

In the past, these problems have been solved by setting the uncertain parameter to its expected value.
However, the solution obtained this way is in many cases far from the true optimal solution.
Flexibility and robustness, two important properties of a solution, only make sense in a framework that takes the uncertainty explicitly into account.
Therefore, early in the development of Mathematical Programming, the theory of Stochastic Programming was developed.
However, due to the much higher computational burden of stochastic programs when compared to their deterministic counterparts, the practical application of this theory was delayed.
With the recent advances in computing technology, it has become feasible to solve the stochastic formulations in reasonable time.
These developments have led to an increased interest in this field, including new applications in many areas \citep{Birge1997a,Sahinidis2004}.

A main difference of stochastic programs as compared to their deterministic counterparts is the significance of the time dimension.
In stochastic programs, over time, information about the value of the stochastic parameters is revealed.
The decisions at any given time may take all past information -- but none that will only be revealed in the future -- into account.
Therefore, the solution must be computed for every possible path that the stochastic variables can take over time.
At the same time, the measurability constraints have to be satisfied.\footnote{\textit{Measurability} constraint is the term used in the literature concerned with probability metrics. In the algorithmic literature, the term \textit{non-anticipativity} constraint is more widespread.}
These constraints describe the fact that a decision at the same time step in two different scenarios must be equal if both scenarios share an identical past until this time step.
These constraints lead to an explosion in the computational complexity of the model, which is the reason why two-stage stochastic programs, for which the history of all paths is identical, are much more common in the literature than multi-stage models \citep{Shapiro2005}.

A convenient way to formulate the measurability constraints is through the use of tree structures.
With the evolution of time, the tree branches, representing several possible future developments for every time step.
This, however, works only for a finite set of scenarios.
In practical applications, continuous probability distributions with an infinite number of scenarios are much more common.
A method must be found to discretize these continuous stochastic processes into discrete tree structures while sacrificing as little accuracy as possible.
In this thesis, a fast, new algorithm is developed that generates an optimal tree approximation from an arbitrary distribution.

Before solving this problem, the notion of optimality of an approximation has to be defined.
Since stochastic processes with continuous probability distributions are infinite dimensional objects, the choice of the distance function to be used in measuring the approximation error is not arbitrary.
In recent papers, the Kantorovich distance has been proposed as the most suitable measurement of approximation quality \citep{Dupacova2003,Heitsch2003,Heitsch2009,Heitsch2009a,Heitsch2010}.
The Kantorovich distance and its properties will be presented in section \ref{sec:math-foundations}.

The approach to scenario tree generation as an approximation problem under a probabilistic metric such as the Kantorovich distance is relatively new.
The first notable usage of a transportation metric in the context of stochastic programming is given by \citet{Pflug2001}.
There, an algorithm for solving the optimal tree approximation problem is proposed that is closely related to one of the algorithms presented in this thesis in section 5.
Many advances in this field have recently been published by the Group of R\"{o}misch \citep{Dupacova2003,Heitsch2003,Heitsch2009,Heitsch2009a,Heitsch2010}.
These papers, however, focus on the problem of scenario reduction, where nodes are deleted from a tree in such a way that the resulting reduced tree is as close as possible to the full tree.

In this thesis, a new algorithm for scenario tree generation combining probability metrics with the Expectation Maximization algorithm \citep{Dempster1977} is derived.
It is organized as follows.
In section 2, the basic concepts of stochastic tree generation and the Kantorovich distance are presented.
In section 3, algorithms for the solution of the optimal approximation problem using state-of-the-art optimization tools are derived.
These algorithms will prove to be too computationally expensive for any practical applications.
In section 4, two theorems are presented that will lead to the development on two algorithms based on the Expectation Maximization algorithm in section 5.
It is shown that the new algorithms not only provide an efficient way to compute the optimal tree approximation, but also yield an estimation of the approximation error for the solution of the stochastic program.
This will prove to be a valuable tool in evaluating the quality of a solution.
\begin{comment}

Many applications in engineering and economics require decisions to be made under uncertainty.
Examples include production planning and supply chain design decisions under uncertain demands and prices, but also robust inventory planning for the case of plant failures.

Many applications in engineering and business require decisions to be made under uncertainty.
Common examples of stochastic parameters in optimization models are future prices, future demand, and plant unit failure.
Optimization models with this kind of parameter appear in many problems such as supply chain design given uncertain demand, and scheduling of the unloading of oil tankers under uncertain arrival times.

In the past, these problems have been solved by setting the parameter to the expected value.
The solution obtained this way, may however be arbitrarily bad for some realizations of the stochastic parameters, and may in fact even be infeasible (see Birge review paper 1997).
Therefore, early in the development of Mathematical Programming, the theory of Stochastic Programming was developed.
However, due to the much higher computational burden of stochastic programs when compared to their deterministic counterparts, the practical application of this theory was delayed.
Because of the recent advances in computing technology, it has become feasible to solve the stochastic formulations in reasonable time.
This has led to a great number of publications in this field in the recent years (see review paper by Nick Sahinidis)

A main difference of Stochastic Programming as compared to the deterministic equivalent models is the importance of the time dimension.
In stochastic programs, while the time evolves, information about the value of the stochastic parameters is revealed.
This means, that the decisions at any given time can take all past information, but none that will only be revealed in the future into account.
Therefore, the solution must be computed for every possible path that the stochastic variables can take over time, while at the same time satisfying the measurability constraints that describe the fact that decisions must be equal if the evolution of the stochastic variables up to the time where this decision has to be made was identical.
These constraints lead to an explosion in the computational complexity of the model, which is the reason why two-stage stochastic programs, where the history of all paths is identical, are much more common than multi-stage models.
(see Shapiro2005)

The most natural way to formulate the measurability constraints is through the use of tree structures.
With the evolution of time, the tree branches off, representing several possible future developments for every time step.
The direct transformation of a stochastic process to a tree is only possible, if the stochastic process can only take on discrete values.
In practical applications, continuous probability distributions are much more common.
A method must be developed to discretize these continuous stochastic processes into discrete tree structures, such that they can be used in a stochastic optimization problem.
In this thesis, a new algorithm is developed that generates the optimal tree of a given complexity from an arbitrary distribution.

The tree generation methods reported in the literature


Decision making under uncertainty is a common problem in business and engineering.
Investment decisions and production plans inherently depend on future demand and prices which are not known at the time the decision is made.
In the past, these problems have been solved using standard mathematical programming, where the uncertain values parameters were replaced by their expected values.
This approach, however, sacrifices flexibility and robustness of the solution, because it will optimize only for the expected values of the parameters.
The error in the solution can become arbitrarily large with respect to the solution obtained when taking the uncertainty into account.

The field of stochastic programming combines probability theory and mathematical programming to find the optimal solution while taking the uncertainty into account.
Due to

Many applications in engineering and economics require decisions to be made under uncertainty.
Examples include production planning and supply chain design decisions under uncertain demands and prices, but also robust inventory planning for the case of plant failures.

Stochastic programming problems are optimization problems under uncertainty, which require a recourse decision after the uncertainty variable has taken on its value.
Problems in which a sequence of such decisions has to be made are called multi-stage stochastic programs.

In this work, two problems in the formulation of multi-stage stochastic programs will be addressed.
in real-world applications, the uncertainty often is introduced as a continuous random variable.
Since in the optimization the recourse problem has to be solved for every possible outcome of the random variable, this leads to infinite dimensional problems.
Even if the underlying random variable is discrete, for multi-stage problems the number of variables grows exponentially with the number of stages.
Methods have to be developed that reduce the complexity of the problem while sacrificing as little accuracy as possible.
An important aspect of this reduction is the preservation of the way that the information about the future over time.
This leads to tree-shaped data structures through which this filtration is encoded.
These properties, that are special to multi-stage problems, makes even measuring the quality of a reduction a difficult enterprise.

This thesis is organized as follows.
First, the theoretical groundwork for the scenario generation is laid out.
The problem of measuring the quality of an approximation is formalized through a metric.
The optimal scenario tree generation will prove to be representable as an MILP/NLP.
In a following section, state-of-the-art MILP and NLP solvers are applied to the problem.
Due to structural reasons, this approach will prove insufficient.
In section \ref{sec:two-theorems}, the derivation of the new method will begin with two theorems which highlight the special structure of the used metric.
The structure of the metric exposed through these theorems will be exploited by the new heuristic algorithm derived in section \ref{sec:expect-max-algos}.
This algorithm is based on the well-known K-Means algorithm.
Promising results will be presented, that show the scalability of the algorithm, and that the quality of the solution is near optimal.
Building on the derivation of the new algorithm, the application of Expectation-Maximization algorithms for the tree generation will be discussed.
\end{comment}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "da"
%%% End:
